{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Question 1\n",
    "\n",
    "Code to get `.arff`:\n",
    "\n",
    "```bash\n",
    "GENRE_1=country\n",
    "GENRE_2=disco\n",
    "GENRE_3=classical\n",
    "\n",
    "# Get the Genres\n",
    "if [ ! -d genres ]; then\n",
    "    curl http://opihi.cs.uvic.ca/sound/genres.tar.gz | tar xz\n",
    "fi\n",
    "\n",
    "# Build collections\n",
    "if [ ! -f q1_${GENRE_1i}.mf ]; then\n",
    "    mkcollection -c q1_${GENRE_1}.mf -l ${GENRE_1} genres/${GENRE_1}\n",
    "fi\n",
    "\n",
    "if [ ! -f q1_${GENRE_2}.mf ]; then\n",
    "    mkcollection -c q1_${GENRE_2}.mf -l ${GENRE_2} genres/${GENRE_2}\n",
    "fi\n",
    "\n",
    "if [ ! -f q1_${GENRE_3}.mf ]; then\n",
    "    mkcollection -c q1_${GENRE_3}.mf -l ${GENRE_3} genres/${GENRE_3}\n",
    "fi\n",
    "\n",
    "cat q1_${GENRE_1}.mf q1_${GENRE_2}.mf q1_${GENRE_3}.mf > q1.mf\n",
    "\n",
    "bextract -sv q1.mf -w q1.arff\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weka: ZeroR\n",
    "\n",
    "```\n",
    "=== Summary ===\n",
    "\n",
    "Correctly Classified Instances         100               33.3333 %\n",
    "Incorrectly Classified Instances       200               66.6667 %\n",
    "Kappa statistic                          0     \n",
    "Mean absolute error                      0.4444\n",
    "Root mean squared error                  0.4714\n",
    "Relative absolute error                100      %\n",
    "Root relative squared error            100      %\n",
    "Coverage of cases (0.95 level)         100      %\n",
    "Mean rel. region size (0.95 level)     100      %\n",
    "Total Number of Instances              300     \n",
    "\n",
    "=== Detailed Accuracy By Class ===\n",
    "\n",
    "                 TP Rate  FP Rate  Precision  Recall   F-Measure  MCC      ROC Area  PRC Area  Class\n",
    "                 1.000    1.000    0.333      1.000    0.500      0.000    0.500     0.333     classical\n",
    "                 0.000    0.000    0.000      0.000    0.000      0.000    0.500     0.333     country\n",
    "                 0.000    0.000    0.000      0.000    0.000      0.000    0.500     0.333     disco\n",
    "Weighted Avg.    0.333    0.333    0.111      0.333    0.167      0.000    0.500     0.333     \n",
    "\n",
    "=== Confusion Matrix ===\n",
    "\n",
    "   a   b   c   <-- classified as\n",
    " 100   0   0 |   a = classical\n",
    " 100   0   0 |   b = country\n",
    " 100   0   0 |   c = disco```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Weka: Naive Bayes\n",
    "\n",
    "```\n",
    "=== Summary ===\n",
    "\n",
    "Correctly Classified Instances         253               84.3333 %\n",
    "Incorrectly Classified Instances        47               15.6667 %\n",
    "Kappa statistic                          0.765 \n",
    "Mean absolute error                      0.1035\n",
    "Root mean squared error                  0.3174\n",
    "Relative absolute error                 23.2891 %\n",
    "Root relative squared error             67.321  %\n",
    "Coverage of cases (0.95 level)          86      %\n",
    "Mean rel. region size (0.95 level)      34.3333 %\n",
    "Total Number of Instances              300     \n",
    "\n",
    "=== Detailed Accuracy By Class ===\n",
    "\n",
    "                 TP Rate  FP Rate  Precision  Recall   F-Measure  MCC      ROC Area  PRC Area  Class\n",
    "                 0.890    0.030    0.937      0.890    0.913      0.872    0.987     0.959     classical\n",
    "                 0.790    0.120    0.767      0.790    0.778      0.665    0.928     0.857     country\n",
    "                 0.850    0.085    0.833      0.850    0.842      0.761    0.963     0.923     disco\n",
    "Weighted Avg.    0.843    0.078    0.846      0.843    0.844      0.766    0.959     0.913     \n",
    "\n",
    "=== Confusion Matrix ===\n",
    "\n",
    "  a  b  c   <-- classified as\n",
    " 89 11  0 |  a = classical\n",
    "  4 79 17 |  b = country\n",
    "  2 13 85 |  c = disco\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weka: J48\n",
    "\n",
    "```\n",
    "=== Summary ===\n",
    "\n",
    "Correctly Classified Instances         241               80.3333 %\n",
    "Incorrectly Classified Instances        59               19.6667 %\n",
    "Kappa statistic                          0.705 \n",
    "Mean absolute error                      0.137 \n",
    "Root mean squared error                  0.3515\n",
    "Relative absolute error                 30.8158 %\n",
    "Root relative squared error             74.5673 %\n",
    "Coverage of cases (0.95 level)          84      %\n",
    "Mean rel. region size (0.95 level)      36.7778 %\n",
    "Total Number of Instances              300     \n",
    "\n",
    "=== Detailed Accuracy By Class ===\n",
    "\n",
    "                 TP Rate  FP Rate  Precision  Recall   F-Measure  MCC      ROC Area  PRC Area  Class\n",
    "                 0.950    0.045    0.913      0.950    0.931      0.896    0.955     0.911     classical\n",
    "                 0.730    0.145    0.716      0.730    0.723      0.582    0.792     0.652     country\n",
    "                 0.730    0.105    0.777      0.730    0.753      0.635    0.826     0.693     disco\n",
    "Weighted Avg.    0.803    0.098    0.802      0.803    0.802      0.705    0.858     0.752     \n",
    "\n",
    "=== Confusion Matrix ===\n",
    "\n",
    "  a  b  c   <-- classified as\n",
    " 95  4  1 |  a = classical\n",
    "  7 73 20 |  b = country\n",
    "  2 25 73 |  c = disco\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weka: SMO\n",
    "\n",
    "```\n",
    "=== Summary ===\n",
    "\n",
    "Correctly Classified Instances         282               94      %\n",
    "Incorrectly Classified Instances        18                6      %\n",
    "Kappa statistic                          0.91  \n",
    "Mean absolute error                      0.2363\n",
    "Root mean squared error                  0.2969\n",
    "Relative absolute error                 53.1667 %\n",
    "Root relative squared error             62.9815 %\n",
    "Coverage of cases (0.95 level)          99.6667 %\n",
    "Mean rel. region size (0.95 level)      66.6667 %\n",
    "Total Number of Instances              300     \n",
    "\n",
    "=== Detailed Accuracy By Class ===\n",
    "\n",
    "                 TP Rate  FP Rate  Precision  Recall   F-Measure  MCC      ROC Area  PRC Area  Class\n",
    "                 1.000    0.010    0.980      1.000    0.990      0.985    0.995     0.980     classical\n",
    "                 0.880    0.030    0.936      0.880    0.907      0.864    0.929     0.865     country\n",
    "                 0.940    0.050    0.904      0.940    0.922      0.882    0.954     0.877     disco\n",
    "Weighted Avg.    0.940    0.030    0.940      0.940    0.940      0.910    0.959     0.908     \n",
    "\n",
    "=== Confusion Matrix ===\n",
    "\n",
    "   a   b   c   <-- classified as\n",
    " 100   0   0 |   a = classical\n",
    "   2  88  10 |   b = country\n",
    "   0   6  94 |   c = disco\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Scikit-Learn\n",
    "\n",
    "Some common code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.99      0.99       100\n",
      "        1.0       0.93      0.92      0.92       100\n",
      "        2.0       0.92      0.93      0.93       100\n",
      "\n",
      "avg / total       0.95      0.95      0.95       300\n",
      "\n",
      "Confusion Matrix:\n",
      "[[99  1  0]\n",
      " [ 0 92  8]\n",
      " [ 1  6 93]]\n",
      "----\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00       100\n",
      "        1.0       1.00      1.00      1.00       100\n",
      "        2.0       1.00      1.00      1.00       100\n",
      "\n",
      "avg / total       1.00      1.00      1.00       300\n",
      "\n",
      "Confusion Matrix:\n",
      "[[100   0   0]\n",
      " [  0 100   0]\n",
      " [  0   0 100]]\n",
      "----\n",
      "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.85      0.66      0.74       100\n",
      "        1.0       0.52      0.53      0.53       100\n",
      "        2.0       0.58      0.70      0.63       100\n",
      "\n",
      "avg / total       0.65      0.63      0.63       300\n",
      "\n",
      "Confusion Matrix:\n",
      "[[66 22 12]\n",
      " [ 8 53 39]\n",
      " [ 4 26 70]]\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "def do_scikit_problem(classifier):\n",
    "    from sklearn.datasets import load_svmlight_file\n",
    "    from sklearn import metrics\n",
    "    \n",
    "    data, target = load_svmlight_file(\"q1.libsvm\")\n",
    "\n",
    "    model = classifier()\n",
    "    model.fit(data, target)\n",
    "\n",
    "    print(model)\n",
    "    \n",
    "    # make predictions\n",
    "    expected = target\n",
    "    predicted = model.predict(data)\n",
    "    \n",
    "    # summarize the fit of the model\n",
    "    print(metrics.classification_report(expected, predicted))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(metrics.confusion_matrix(expected, predicted))\n",
    "    print(\"----\")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "do_scikit_problem(LogisticRegression)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "do_scikit_problem(DecisionTreeClassifier)\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "do_scikit_problem(BernoulliNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Question 2\n",
    "\n",
    "First let's traverse the tree and build the vectors. Then we'll print out the probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word       pos     neg    \n",
      "awful       3.4  12.2\n",
      "bad        28.0  54.5\n",
      "boring      5.4  17.5\n",
      "dull        2.5  10.1\n",
      "effective  15.4   8.6\n",
      "great      48.5  32.0\n",
      "hilarious  13.2   5.9\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "\n",
    "hotwords = [ 'awful', 'bad', 'boring', 'dull', 'effective', 'great', 'hilarious' ]\n",
    "dataset_size = 1000\n",
    "\n",
    "def process_sample(string):\n",
    "    instance_vector = [False] * len(hotwords)\n",
    "    for i, word in enumerate(hotwords):\n",
    "        if word in string:\n",
    "            instance_vector[i] = True\n",
    "    return instance_vector\n",
    "\n",
    "def get_samples(polarity):\n",
    "    data = []\n",
    "    for file_name in listdir(\"q2_data/\"+polarity):\n",
    "        file_descriptor = open(\"q2_data/\"+polarity+\"/\"+file_name)\n",
    "        file_contents = file_descriptor.read()\n",
    "        data.append(file_contents)\n",
    "        file_descriptor.close()\n",
    "    return data\n",
    "        \n",
    "\n",
    "# Load/Parse the data\n",
    "pos = [process_sample(sample) for sample in get_samples(\"pos\")]\n",
    "neg = [process_sample(sample) for sample in get_samples(\"neg\")]\n",
    "\n",
    "# Calc probabilities\n",
    "## Positives\n",
    "pos_probabilities = [0] * len(hotwords)\n",
    "for instance in pos:\n",
    "    for i,exists in enumerate(instance):\n",
    "        if exists:\n",
    "            pos_probabilities[i] += 1\n",
    "for i,val in enumerate(pos_probabilities):\n",
    "    pos_probabilities[i] = float(val) / 10 # (1000 instances, 100%, so 10)\n",
    "## Negatives\n",
    "neg_probabilities = [0] * len(hotwords)\n",
    "for instance in neg:\n",
    "    for i,exists in enumerate(instance):\n",
    "        if exists:\n",
    "            neg_probabilities[i] += 1\n",
    "for i,val in enumerate(neg_probabilities):\n",
    "    neg_probabilities[i] = float(val) / 10\n",
    "## Total\n",
    "total_probabilities = [0] * len(hotwords)\n",
    "for instance in neg + pos:\n",
    "    for i,exists in enumerate(instance):\n",
    "        if exists:\n",
    "            total_probabilities[i] += 1\n",
    "for i,val in enumerate(total_probabilities):\n",
    "    total_probabilities[i] = float(val) / 10\n",
    "\n",
    "# Print all nice like.\n",
    "print('{:10s} {:7s} {:7s}'.format(\"word\", \"pos\", \"neg\"))\n",
    "\n",
    "for i,pair in enumerate(pos_probabilities):\n",
    "    print('{:10s} {:4.1f}  {:4.1f}'.format(hotwords[i], pos_probabilities[i], neg_probabilities[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Part 2)\n",
    "\n",
    "Since half the reviews are negative, and half are positive, there is a 50% chance of any given sample being positive, and a 50% change of it being negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prob_polarity = {\n",
    "    'pos': .50,\n",
    "    'neg': .50\n",
    "}\n",
    "\n",
    "samples = {\n",
    "    'pos': get_samples('pos'),\n",
    "    'neg': get_samples('neg')\n",
    "}\n",
    "\n",
    "compound_probabilities = {\n",
    "    'pos': [prob * prob_polarity['pos'] for prob in pos_probabilities],\n",
    "    'neg': [prob * prob_polarity['neg'] for prob in neg_probabilities]\n",
    "}\n",
    "\n",
    "def classify(instance_vector):\n",
    "    pos_numerator = prob_polarity['pos']\n",
    "    neg_numerator = prob_polarity['neg']\n",
    "    \n",
    "    pos_denominator = 1 # We can safely start at 1.\n",
    "    neg_denominator = 1\n",
    "    \n",
    "    for i,present in enumerate(instance_vector):\n",
    "        if present:\n",
    "            pos_numerator *= compound_probabilities['pos'][i]\n",
    "            neg_numerator *= compound_probabilities['neg'][i]\n",
    "            \n",
    "            pos_denominator *= total_probabilities[i]\n",
    "            neg_denominator *= total_probabilities[i]\n",
    "    pos = pos_numerator / pos_denominator\n",
    "    neg = neg_numerator / neg_denominator\n",
    "    if pos > neg:\n",
    "        return 'pos'\n",
    "    else:\n",
    "        return 'neg'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " pos  neg\n",
      " 452  548 pos\n",
      " 153  847 neg\n",
      "Accuracy: 0.6495\n"
     ]
    }
   ],
   "source": [
    "pos_as_pos = 0\n",
    "pos_as_neg = 0\n",
    "for i in [classify(sample) for sample in pos]:\n",
    "    if i == 'pos':\n",
    "        pos_as_pos += 1\n",
    "    elif i == 'neg':\n",
    "        pos_as_neg += 1\n",
    "\n",
    "neg_as_pos = 0\n",
    "neg_as_neg = 0\n",
    "for i in [classify(sample) for sample in neg]:\n",
    "    if i == 'pos':\n",
    "        neg_as_pos += 1\n",
    "    elif i == 'neg':\n",
    "        neg_as_neg += 1\n",
    "\n",
    "print(\" pos  neg\\n{:4d} {:4d} pos\\n{:4d} {:4d} neg\".format(pos_as_pos, pos_as_neg, neg_as_pos, neg_as_neg))\n",
    "print(\"Accuracy: {}\".format(float(pos_as_pos + neg_as_neg) / float(pos_as_pos + pos_as_neg + neg_as_neg + neg_as_pos)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Part 3, Crossfold validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold number: 0\n",
      " pos  neg\n",
      "  70   30 pos\n",
      "  21   79 neg\n",
      "Accuracy: 0.745\n",
      "\n",
      "\n",
      "For fold number: 1\n",
      " pos  neg\n",
      "  50   50 pos\n",
      "  14   86 neg\n",
      "Accuracy: 0.68\n",
      "\n",
      "\n",
      "For fold number: 2\n",
      " pos  neg\n",
      "  38   62 pos\n",
      "  10   90 neg\n",
      "Accuracy: 0.64\n",
      "\n",
      "\n",
      "For fold number: 3\n",
      " pos  neg\n",
      "  47   53 pos\n",
      "  16   84 neg\n",
      "Accuracy: 0.655\n",
      "\n",
      "\n",
      "For fold number: 4\n",
      " pos  neg\n",
      "  48   52 pos\n",
      "  18   82 neg\n",
      "Accuracy: 0.65\n",
      "\n",
      "\n",
      "For fold number: 5\n",
      " pos  neg\n",
      "  42   58 pos\n",
      "  20   80 neg\n",
      "Accuracy: 0.61\n",
      "\n",
      "\n",
      "For fold number: 6\n",
      " pos  neg\n",
      "  46   54 pos\n",
      "   7   93 neg\n",
      "Accuracy: 0.695\n",
      "\n",
      "\n",
      "For fold number: 7\n",
      " pos  neg\n",
      "  46   54 pos\n",
      "  15   85 neg\n",
      "Accuracy: 0.655\n",
      "\n",
      "\n",
      "For fold number: 8\n",
      " pos  neg\n",
      "  43   57 pos\n",
      "  19   81 neg\n",
      "Accuracy: 0.62\n",
      "\n",
      "\n",
      "For fold number: 9\n",
      " pos  neg\n",
      "  47   53 pos\n",
      "  11   89 neg\n",
      "Accuracy: 0.68\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_folds(polarity):\n",
    "    return zip(*[iter(get_samples(polarity))]*100)\n",
    "\n",
    "def get_crossfolds(folds):\n",
    "    crossfolds = []\n",
    "    for i in range(0, 10-1):\n",
    "        crossfolds.append(folds[i:] + folds[:i+1])\n",
    "    return crossfolds\n",
    "    \n",
    "def get_probabilities(processed_instances):\n",
    "    probabilities = [0] * len(hotwords)\n",
    "    for instance in processed_instances:\n",
    "        for i,exists in enumerate(instance):\n",
    "            if exists:\n",
    "                probabilities[i] += 1\n",
    "    for i,val in enumerate(probabilities):\n",
    "        probabilities[i] = (float(val) / len(processed_instances)) * 100\n",
    "    return probabilities\n",
    "\n",
    "def classify_crossfold(pos_fold_probabilities, neg_fold_probabilities, instance_vector):\n",
    "    compound_probabilities = {\n",
    "        'pos': [prob * .5 for prob in pos_fold_probabilities],\n",
    "        'neg': [prob * .5 for prob in neg_fold_probabilities]\n",
    "    }\n",
    "    \n",
    "    total_probabilities = [x + y for x,y in zip(compound_probabilities[\"pos\"], compound_probabilities[\"neg\"])]\n",
    "    \n",
    "    pos_numerator = prob_polarity['pos']\n",
    "    neg_numerator = prob_polarity['neg']\n",
    "    \n",
    "    pos_denominator = 1 # We can safely start at 1.\n",
    "    neg_denominator = 1\n",
    "    \n",
    "    for i,present in enumerate(instance_vector):\n",
    "        if present:\n",
    "            pos_numerator *= compound_probabilities['pos'][i]\n",
    "            neg_numerator *= compound_probabilities['neg'][i]\n",
    "            \n",
    "            pos_denominator *= total_probabilities[i]\n",
    "            neg_denominator *= total_probabilities[i]\n",
    "    pos = pos_numerator / pos_denominator\n",
    "    neg = neg_numerator / neg_denominator\n",
    "    if pos > neg:\n",
    "        return 'pos'\n",
    "    else:\n",
    "        return 'neg'\n",
    "\n",
    "pos_folds = []\n",
    "for chunk in get_folds(\"pos\"):\n",
    "    samples = []\n",
    "    for sample in chunk:\n",
    "        samples.append(process_sample(sample))\n",
    "    pos_folds.append(samples)\n",
    "    \n",
    "neg_folds = []\n",
    "for chunk in get_folds(\"neg\"):\n",
    "    samples = []\n",
    "    for sample in chunk:\n",
    "        samples.append(process_sample(sample))\n",
    "    neg_folds.append(samples)\n",
    "\n",
    "import itertools\n",
    "pos_crossfold_probabilities = [get_probabilities(crossfold) for crossfold in itertools.chain(*get_crossfolds(pos_folds))]\n",
    "neg_crossfold_probabilities = [get_probabilities(crossfold) for crossfold in itertools.chain(*get_crossfolds(neg_folds))]\n",
    "\n",
    "def acc_and_confusion_for_fold(fold_number):\n",
    "    pos_as_pos = 0\n",
    "    pos_as_neg = 0\n",
    "    for i in [classify_crossfold(pos_crossfold_probabilities[fold_number], neg_crossfold_probabilities[fold_number], sample) for sample in pos_folds[fold_number]]:\n",
    "        if i == 'pos':\n",
    "            pos_as_pos += 1\n",
    "        elif i == 'neg':\n",
    "            pos_as_neg += 1\n",
    "\n",
    "    neg_as_pos = 0\n",
    "    neg_as_neg = 0\n",
    "    for i in [classify_crossfold(pos_crossfold_probabilities[fold_number], neg_crossfold_probabilities[fold_number], sample) for sample in neg_folds[fold_number]]:\n",
    "        if i == 'pos':\n",
    "            neg_as_pos += 1\n",
    "        elif i == 'neg':\n",
    "            neg_as_neg += 1\n",
    "            \n",
    "    print(\"For fold number: \" + str(fold_number))\n",
    "    print(\" pos  neg\\n{:4d} {:4d} pos\\n{:4d} {:4d} neg\".format(pos_as_pos, pos_as_neg, neg_as_pos, neg_as_neg))\n",
    "    print(\"Accuracy: {}\".format(float(pos_as_pos + neg_as_neg) / float(pos_as_pos + pos_as_neg + neg_as_neg + neg_as_pos)))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "[acc_and_confusion_for_fold(i) for i in range(0,10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Part 4, Generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([3.4, 28.0, 5.4, 2.5, 15.4, 48.5, 13.2], 60.19179438579083)\n",
      "[]\n",
      "([3.4, 28.0, 5.4, 2.5, 15.4, 48.5, 13.2], 97.77804699769412)\n",
      "[]\n",
      "([3.4, 28.0, 5.4, 2.5, 15.4, 48.5, 13.2], 26.357732538160093)\n",
      "['bad', 'great']\n",
      "([3.4, 28.0, 5.4, 2.5, 15.4, 48.5, 13.2], 16.56455714643361)\n",
      "['bad', 'great']\n",
      "([3.4, 28.0, 5.4, 2.5, 15.4, 48.5, 13.2], 95.38887198005234)\n",
      "[]\n",
      "([12.2, 54.5, 17.5, 10.1, 8.6, 32.0, 5.9], 49.8602127130661)\n",
      "['bad']\n",
      "([12.2, 54.5, 17.5, 10.1, 8.6, 32.0, 5.9], 17.282635757639852)\n",
      "['bad', 'boring', 'great']\n",
      "([12.2, 54.5, 17.5, 10.1, 8.6, 32.0, 5.9], 81.91954951438164)\n",
      "[]\n",
      "([12.2, 54.5, 17.5, 10.1, 8.6, 32.0, 5.9], 29.723791755111474)\n",
      "['bad', 'great']\n",
      "([12.2, 54.5, 17.5, 10.1, 8.6, 32.0, 5.9], 3.319642946796786)\n",
      "['awful', 'bad', 'boring', 'dull', 'effective', 'great', 'hilarious']\n"
     ]
    }
   ],
   "source": [
    "def generate_instance(polarity, random_number):\n",
    "    instance = []\n",
    "    if polarity == \"pos\":\n",
    "        probs = pos_probabilities \n",
    "    else:\n",
    "        probs = neg_probabilities  \n",
    "    print(probs, random_number)\n",
    "    for i,item in enumerate(probs):\n",
    "        if random_number < item:\n",
    "            instance.append(hotwords[i])\n",
    "    return instance\n",
    "\n",
    "from random import random\n",
    "for polarity in [\"pos\", \"neg\"]:\n",
    "    for i in range(0, 5):\n",
    "        print(generate_instance(polarity, random() * 100))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my experience with movie reviews this is basically par for the course, most reviews are totally meaningless."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
